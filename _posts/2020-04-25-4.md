---
layout:     post
title:      最小二乘估计
date:       2020-04-25
author:     Minjun Huang
header-img: img/tag-bg-o.jpg
catalog: true
tags:
    - 计量经济学

---

<head>
    <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>
    <script type="text/x-mathjax-config">
        MathJax.Hub.Config({
            tex2jax: {
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
            inlineMath: [['$','$']]
            }
        });
    </script>
</head>
## 古典线性模型假定

- 线性假定：$\boldsymbol{y}=\boldsymbol{X \beta} + \boldsymbol{\varepsilon}$，共有$K$个解释变量，$n$个观测
- 严格外生性：$\text{E}(\varepsilon_i \mid \boldsymbol{X})=0$，即扰动项与所有解释变量均不相关
- 球型扰动项：$\text{Var}(\boldsymbol{\varepsilon} \mid \boldsymbol{X})=\sigma^2 \boldsymbol{I}_n$，即扰动项不存在条件异方差与自相关
- 无严重多重共线性：$\text{rank}(\boldsymbol{X})=K$，即数据矩阵$\boldsymbol{X}$满列秩
- 正态扰动项：$\boldsymbol{\varepsilon} \| \boldsymbol{X} \sim N(\mathbf{0},\sigma^2 \boldsymbol{I}_n)$

## OLS推导

&emsp;&emsp;即最小化残差平方和SSR$\displaystyle \sum_{i=1}^{n} e\_{i}^{2}$，设$\boldsymbol{e}=(e_1,\cdots,e_n)'$，则SSR可以表示为$\boldsymbol{e}'\boldsymbol{e}$，记$\boldsymbol{b}$为使得SSR最小的$\boldsymbol{\beta}$值。



$$
\begin{aligned}
\min_{\boldsymbol{\beta }} \,\,\boldsymbol{e}'\boldsymbol{e}&=\left( \boldsymbol{y}-\boldsymbol{X\beta } \right) '\left( \boldsymbol{y}-\boldsymbol{X\beta } \right) 
\\
&=\boldsymbol{y}'\boldsymbol{y}-2\boldsymbol{y}'\boldsymbol{X\beta }+\boldsymbol{\beta }'\boldsymbol{X}'\boldsymbol{X\beta }
\end{aligned}
$$


有一阶条件



$$
\frac{\partial \left( \boldsymbol{e}'\boldsymbol{e} \right)}{\partial \boldsymbol{\beta }}=-2\boldsymbol{X}'\boldsymbol{y }+2\boldsymbol{X}'\boldsymbol{X\beta }=\mathbf{0}
$$



解得



$$
\boldsymbol{b}=\left( \boldsymbol{X}'\boldsymbol{X} \right) ^{-1}\boldsymbol{X}'\boldsymbol{y}
$$



并且二阶条件



$$
\frac{\partial ^2\left( \boldsymbol{e}'\boldsymbol{e} \right)}{\partial \boldsymbol{\beta }\partial \boldsymbol{\beta }'}=2\boldsymbol{X}'\boldsymbol{X}
$$


由于$\boldsymbol{X}$满列秩，故$\boldsymbol{X}'\boldsymbol{X}$正定，因此$\boldsymbol{b}$为极小值。



## 高斯-马尔可夫定理

#### 线性性

&emsp;&emsp;由于$\boldsymbol{b}=(\boldsymbol{X}'\boldsymbol{X})^{-1}\boldsymbol{X}'\boldsymbol{y}$，故OLS估计量为关于$\boldsymbol{y}$的线性组合。

#### 无偏性

&emsp;&emsp;由于$\boldsymbol{b}=(\boldsymbol{X}'\boldsymbol{X})^{-1}\boldsymbol{X}'\boldsymbol{y}$ ，展开得


$$
\begin{aligned}
\boldsymbol{b}&=\left( \boldsymbol{X}'\boldsymbol{X} \right) ^{-1}\boldsymbol{X}'\left( \boldsymbol{X\beta }+\boldsymbol{\varepsilon } \right) 
\\
&=\boldsymbol{\beta }+\left( \boldsymbol{X}'\boldsymbol{X} \right) ^{-1}\boldsymbol{X}'\boldsymbol{\varepsilon }
\end{aligned}
$$


由严格外生性得$\text{E}\left( \boldsymbol{b}\mid \boldsymbol{X} \right) =\boldsymbol{\beta }$。

#### 有效性

&emsp;&emsp;先求OLS估计量$\boldsymbol{b}$的条件方差，由于$\boldsymbol{\beta}$是常数矩阵，故可略去。由球型扰动项假设，下式成立


$$
\begin{aligned}
\text{Var}\left( \boldsymbol{b}\mid \boldsymbol{X} \right) &=\text{Var}\left[ \left( \boldsymbol{X}'\boldsymbol{X} \right) ^{-1}\boldsymbol{X}'\boldsymbol{\varepsilon }\mid \boldsymbol{X} \right] 
\\
&=\left( \boldsymbol{X}'\boldsymbol{X} \right) ^{-1}\boldsymbol{X}'\text{Var}\left( \boldsymbol{\varepsilon }\mid \boldsymbol{X} \right) \boldsymbol{X}\left( \boldsymbol{X}'\boldsymbol{X} \right) ^{-1}
\\
&=\sigma ^2\left( \boldsymbol{X}'\boldsymbol{X} \right) ^{-1}
\end{aligned}
$$


&emsp;&emsp;对于某个线性无偏估计量$\hat{\boldsymbol{\beta}}=\boldsymbol{Cy}$，并且对于某个矩阵$\boldsymbol{D}$，有$\boldsymbol{C}=\boldsymbol{D}+(\boldsymbol{X}’\boldsymbol{X})^{-1}\boldsymbol{X}'$成立。根据无偏性，可以得到


$$
\text{E}\left( \boldsymbol{\hat{\beta}}\mid \boldsymbol{X} \right) =\text{E}\left( \boldsymbol{DX\beta }+\boldsymbol{D\varepsilon }+\boldsymbol{b}\mid \boldsymbol{X} \right) =\boldsymbol{\beta }
$$


显然有$\boldsymbol{DX \beta}=\mathbf{0}$成立，进一步有$\boldsymbol{DX}=\mathbf{0}$。考虑下式


$$
\boldsymbol{\hat{\beta}}-\boldsymbol{\beta }=\boldsymbol{D\varepsilon }+\boldsymbol{b}-\boldsymbol{\beta }=\boldsymbol{C\varepsilon }
$$


由于$\boldsymbol{\beta}$为常数矩阵，因此


$$
\text{Var}\left( \boldsymbol{\hat{\beta}}\mid \boldsymbol{X} \right) =\text{Var}\left( \boldsymbol{C\varepsilon }\mid \boldsymbol{X} \right) =\sigma ^2\boldsymbol{CC}'
$$


考虑下式


$$
\begin{aligned}
\boldsymbol{CC}'&=\left[ \boldsymbol{D}+\left( \boldsymbol{X}'\boldsymbol{X} \right) ^{-1}\boldsymbol{X}' \right] \left[ \boldsymbol{D}+\left( \boldsymbol{X}'\boldsymbol{X} \right) ^{-1}\boldsymbol{X}' \right] '
\\
&=\boldsymbol{DD}'+\boldsymbol{DX}\left( \boldsymbol{X}'\boldsymbol{X} \right) ^{-1}+\left( \boldsymbol{X}'\boldsymbol{X} \right) ^{-1}\left( \boldsymbol{DX} \right) '+\left( \boldsymbol{X}'\boldsymbol{X} \right) ^{-1}
\\
&=\boldsymbol{DD}'+\left( \boldsymbol{X}'\boldsymbol{X} \right) ^{-1}
\end{aligned}
$$


由于$\boldsymbol{D}\boldsymbol{D}’$为半正定矩阵，故$\text{Var}\left( \boldsymbol{\hat{\beta}}\mid \boldsymbol{X} \right) \geqslant \text{Var}\left( \boldsymbol{b}\mid \boldsymbol{X} \right) $。



&emsp;&emsp;证毕。